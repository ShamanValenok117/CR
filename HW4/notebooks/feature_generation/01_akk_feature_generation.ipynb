{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-required-libraries\" data-toc-modified-id=\"Loading-required-libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading required libraries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-prepared-dataset\" data-toc-modified-id=\"Loading-prepared-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Loading prepared dataset</a></span></li></ul></li><li><span><a href=\"#Making-high-quality-wine-features-from-medium-quality-wine\" data-toc-modified-id=\"Making-high-quality-wine-features-from-medium-quality-wine-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Making high quality wine features from medium quality wine</a></span><ul class=\"toc-item\"><li><span><a href=\"#Making-feature-statistic-analysis\" data-toc-modified-id=\"Making-feature-statistic-analysis-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Making feature statistic analysis</a></span></li><li><span><a href=\"#Preparing-function\" data-toc-modified-id=\"Preparing-function-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Preparing function</a></span></li><li><span><a href=\"#Generating-new-samples\" data-toc-modified-id=\"Generating-new-samples-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Generating new samples</a></span></li><li><span><a href=\"#Spliting-to-Train-Test-Validation-and-adding-new-samples-ONLY-to-Train-dataset\" data-toc-modified-id=\"Spliting-to-Train-Test-Validation-and-adding-new-samples-ONLY-to-Train-dataset-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Spliting to Train Test Validation and adding new samples ONLY to Train dataset</a></span></li><li><span><a href=\"#Making-50-duplicates-of-class-2-in-Test-and-Validation-datasets\" data-toc-modified-id=\"Making-50-duplicates-of-class-2-in-Test-and-Validation-datasets-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Making 50 duplicates of class 2 in Test and Validation datasets</a></span></li><li><span><a href=\"#Saving\" data-toc-modified-id=\"Saving-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Saving</a></span></li></ul></li><li><span><a href=\"#Making-samples-by-MEAN-OF-TWO-RANDOM-CHOSEN-SAMPLES\" data-toc-modified-id=\"Making-samples-by-MEAN-OF-TWO-RANDOM-CHOSEN-SAMPLES-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Making samples by MEAN OF TWO RANDOM CHOSEN SAMPLES</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparing-Function\" data-toc-modified-id=\"Preparing-Function-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Preparing Function</a></span></li><li><span><a href=\"#Generating-new-samples\" data-toc-modified-id=\"Generating-new-samples-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generating new samples</a></span></li><li><span><a href=\"#Spliting-to-Train-Test-Validation-and-adding-new-samples-ONLY-to-Train-dataset\" data-toc-modified-id=\"Spliting-to-Train-Test-Validation-and-adding-new-samples-ONLY-to-Train-dataset-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Spliting to Train Test Validation and adding new samples ONLY to Train dataset</a></span></li><li><span><a href=\"#Making-50-duplicates-of-class-2-in-Test-and-Validation-datasets\" data-toc-modified-id=\"Making-50-duplicates-of-class-2-in-Test-and-Validation-datasets-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Making 50 duplicates of class 2 in Test and Validation datasets</a></span></li><li><span><a href=\"#Saving\" data-toc-modified-id=\"Saving-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Saving</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature_generation\n",
    "\n",
    "Here the 2 approaches of feature generation are collected.\n",
    "\n",
    "Will be used the following approaches: \n",
    "- generate new samples by making mean of two samples from class 2\n",
    "- generate new samples from class 1 + unique feature values (special for class 2) \n",
    "\n",
    "## Loading required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:03:08.012396Z",
     "start_time": "2021-11-12T07:03:05.997393Z"
    }
   },
   "outputs": [],
   "source": [
    "# matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:03:08.902398Z",
     "start_time": "2021-11-12T07:03:08.842397Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('../../data/intermid/X_wo_missed_values.csv',index_col=0)\n",
    "y = pd.read_csv('../../data/intermid/y_wo_missed_values.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:03:11.913402Z",
     "start_time": "2021-11-12T07:03:11.903402Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([X,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T16:01:45.483433Z",
     "start_time": "2021-11-11T16:01:45.473433Z"
    }
   },
   "source": [
    "## Making high quality wine features from medium quality wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making feature statistic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.132566Z",
     "start_time": "2021-11-12T06:41:56.112566Z"
    }
   },
   "outputs": [],
   "source": [
    "features_for_high_quality = [\n",
    "    'chlorides',\n",
    "    'density',\n",
    "    'pH',\n",
    "    'alcohol',\n",
    "    'fixed acidity',\n",
    "    'volatile acidity',\n",
    "    'sulphates'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.212566Z",
     "start_time": "2021-11-12T06:41:56.132566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>criteria_student_1samp</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chlorides</td>\n",
       "      <td>-8.546</td>\n",
       "      <td>0.00103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>density</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>0.08152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pH</td>\n",
       "      <td>2.437</td>\n",
       "      <td>0.07146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>3.701</td>\n",
       "      <td>0.02081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fixed acidity</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.65901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>volatile acidity</td>\n",
       "      <td>-1.425</td>\n",
       "      <td>0.22731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sulphates</td>\n",
       "      <td>-1.601</td>\n",
       "      <td>0.18473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  criteria_student_1samp  p_value\n",
       "0         chlorides                  -8.546  0.00103\n",
       "1           density                  -2.316  0.08152\n",
       "2                pH                   2.437  0.07146\n",
       "3           alcohol                   3.701  0.02081\n",
       "4     fixed acidity                   0.476  0.65901\n",
       "5  volatile acidity                  -1.425  0.22731\n",
       "6         sulphates                  -1.601  0.18473"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the statistical relevance :\n",
    "features_for_high_quality_statistic = {'feature':[],\n",
    "                                      'criteria_student_1samp':[],\n",
    "                                      'p_value':[]}\n",
    "\n",
    "for i in features_for_high_quality:\n",
    "    high_array = np.array(df.loc[df.quality==2,:][i]) # 2 = quality 'high'\n",
    "    medium_array = np.array(df.loc[df.quality==1,:][i]) # 1 = quality 'medium'\n",
    "    \n",
    "    criteria_studdent_1samp = stats.ttest_1samp(a=high_array,popmean=np.mean(medium_array) )\n",
    "    \n",
    "    features_for_high_quality_statistic['feature'].append(i)\n",
    "    features_for_high_quality_statistic['criteria_student_1samp'].append(round(criteria_studdent_1samp[0],3))\n",
    "    features_for_high_quality_statistic['p_value'].append(round(criteria_studdent_1samp[1],5))\n",
    "\n",
    "pd.DataFrame(features_for_high_quality_statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features: __chlorides__ and __alcohol__ is statistical significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing function\n",
    "\n",
    "Make samples from medium wine with changing chlorides and alcohol features to correspond high_quality wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.242566Z",
     "start_time": "2021-11-12T06:41:56.222566Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_new_sample_from_medium(n,dataset):\n",
    "    '''\n",
    "        MAKE NEW SAMPLE FROM MEDIUM QUALITY WINES ADDING chlorides AND alcohol\n",
    "        N - new samples amount\n",
    "    '''\n",
    "\n",
    "    high_chlorides = np.array(dataset.loc[dataset.quality==2,'chlorides'])\n",
    "    high_alcohol = np.array(dataset.loc[dataset.quality==2,'alcohol'])\n",
    "\n",
    "    new_item_chlorides = stats.norm.rvs(loc=np.mean(high_chlorides), scale=np.std(high_chlorides),size=n)\n",
    "    new_item_alcohol = stats.norm.rvs(loc=np.mean(high_alcohol), scale=np.std(high_alcohol),size=n)\n",
    "\n",
    "    medium_quality_wines = dataset[dataset.quality==1]\n",
    "\n",
    "    new_item = np.random.choice(medium_quality_wines.index,size=n)\n",
    "\n",
    "    new_item = medium_quality_wines.loc[new_item,:]\n",
    "\n",
    "    new_item.chlorides = new_item_chlorides\n",
    "    new_item.alcohol = new_item_alcohol\n",
    "    new_item.quality = [2]*n\n",
    "    \n",
    "    dataset = dataset.append(new_item)\n",
    "    \n",
    "    return new_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.265567Z",
     "start_time": "2021-11-12T06:41:56.242566Z"
    }
   },
   "outputs": [],
   "source": [
    "new_high_quality_samples = make_new_sample_from_medium(3000,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.284568Z",
     "start_time": "2021-11-12T06:41:56.268567Z"
    }
   },
   "outputs": [],
   "source": [
    "index_high_quality = df[df.quality==2].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting to Train Test Validation and adding new samples ONLY to Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.324568Z",
     "start_time": "2021-11-12T06:41:56.284568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 137, 3758], dtype=int64),\n",
       " array([  64, 1494,    3], dtype=int64),\n",
       " array([ 45, 994,   2], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(index=index_high_quality).iloc[:,:-1],\n",
    "                                                    df.drop(index=index_high_quality).iloc[:,-1],test_size=.4,random_state=255)\n",
    "\n",
    "#adding high quality wines\n",
    "X_test = X_test.append(df.iloc[index_high_quality,:-1])\n",
    "y_test = y_test.append(df.iloc[index_high_quality,-1])\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test,y_test,test_size=.4,random_state=255)\n",
    "\n",
    "np.bincount(y_train), np.bincount(y_test),np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.344568Z",
     "start_time": "2021-11-12T06:41:56.324568Z"
    }
   },
   "outputs": [],
   "source": [
    "#adding generated examples to train dataset \n",
    "X_train = X_train.append(new_high_quality_samples.iloc[:,:-1])\n",
    "y_train = y_train.append(new_high_quality_samples.iloc[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.364568Z",
     "start_time": "2021-11-12T06:41:56.344568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 137, 3758, 3000], dtype=int64),\n",
       " array([  64, 1494,    3], dtype=int64),\n",
       " array([ 45, 994,   2], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train), np.bincount(y_test),np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making 50 duplicates of class 2 in Test and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.384568Z",
     "start_time": "2021-11-12T06:41:56.364568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  64, 1494,   50], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making 50 duplicates of high_quality wine to X_test and y_test:\n",
    "X_y_test = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "a = X_y_test[X_y_test.quality==2]\n",
    "\n",
    "a = a.sample(n=47,random_state=255,replace=True)\n",
    "\n",
    "X_y_test = pd.concat([a,X_y_test],axis=0)\n",
    "\n",
    "\n",
    "X_test = X_y_test.iloc[:,:-1]\n",
    "y_test = X_y_test.iloc[:,-1]\n",
    "\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.414568Z",
     "start_time": "2021-11-12T06:41:56.384568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45, 994,  50], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making 100 duplicates of high_quality wine to X_val and y_val:\n",
    "X_y_val = pd.concat([X_val,y_val],axis=1)\n",
    "\n",
    "a = X_y_val[X_y_val.quality==2]\n",
    "\n",
    "a = a.sample(n=48,random_state=255,replace=True)\n",
    "\n",
    "X_y_val = pd.concat([a,X_y_val],axis=0)\n",
    "\n",
    "\n",
    "X_val = X_y_val.iloc[:,:-1]\n",
    "y_val = X_y_val.iloc[:,-1]\n",
    "\n",
    "np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.444568Z",
     "start_time": "2021-11-12T06:41:56.414568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:\n",
      "0\t1\t2\n",
      "-----------------------------------\n",
      "[ 137 3758 3000]  <- train\n",
      "[  64 1494   50]  <- test\n",
      "[ 45 994  50]  <- validation\n"
     ]
    }
   ],
   "source": [
    "print('class:')\n",
    "print('0\\t1\\t2')\n",
    "print('-'*35)\n",
    "print(np.bincount(y_train), ' <- train')\n",
    "print(np.bincount(y_test), ' <- test')\n",
    "print(np.bincount(y_val), ' <- validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.464568Z",
     "start_time": "2021-11-12T06:41:56.444568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 137, 3758, 3000], dtype=int64),\n",
       " array([  64, 1494,   50], dtype=int64),\n",
       " array([ 45, 994,  50], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train), np.bincount(y_test),np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:41:56.894568Z",
     "start_time": "2021-11-12T06:41:56.464568Z"
    }
   },
   "outputs": [],
   "source": [
    "#saving to file:\n",
    "X_train.to_csv('X_train.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "\n",
    "X_test.to_csv('X_test.csv')\n",
    "y_test.to_csv('y_test.csv')\n",
    "\n",
    "X_val.to_csv('X_val.csv')\n",
    "y_val.to_csv('y_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making samples by MEAN OF TWO RANDOM CHOSEN SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:16:43.607577Z",
     "start_time": "2021-11-12T07:16:43.587577Z"
    }
   },
   "outputs": [],
   "source": [
    "index_high_quality = df[df.quality==2].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:39:12.338582Z",
     "start_time": "2021-11-12T07:39:12.328582Z"
    }
   },
   "source": [
    "### Preparing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:06:07.349650Z",
     "start_time": "2021-11-12T07:06:07.329650Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_new_sample(n,dataset):\n",
    "    '''\n",
    "        MAKE NEW SAMPLE FROM MEAN OF TWO RANDOM CHOSEN SAMPLES\n",
    "        N - new samples amount\n",
    "    '''\n",
    "    for i in range(n):\n",
    "        index_1, index_2 = np.random.randint(low=0,high=len(dataset)-1,size=2)\n",
    "        b = np.array(dataset)\n",
    "        new_item = (b[index_1]+b[index_2])/2\n",
    "        new_item = pd.DataFrame(new_item.reshape(1,-1), columns=dataset.columns)\n",
    "        dataset = dataset.append(new_item)\n",
    "    dataset.reset_index(inplace=True)\n",
    "    dataset.drop(columns='index',inplace=True)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:17:31.323645Z",
     "start_time": "2021-11-12T07:17:31.313645Z"
    }
   },
   "outputs": [],
   "source": [
    "high_quality_df = df[df.quality==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:17:32.723647Z",
     "start_time": "2021-11-12T07:17:32.703646Z"
    }
   },
   "outputs": [],
   "source": [
    "high_quality_df_pH = list(high_quality_df.pH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:17:36.614652Z",
     "start_time": "2021-11-12T07:17:34.734649Z"
    }
   },
   "outputs": [],
   "source": [
    "a = make_new_sample(3000,high_quality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:18:07.368695Z",
     "start_time": "2021-11-12T07:18:07.348695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2994,   11], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['check'] = a.pH.apply(lambda x: 1 if x in high_quality_df_pH else 0)\n",
    "np.bincount(a.check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:19:46.241834Z",
     "start_time": "2021-11-12T07:19:46.231834Z"
    }
   },
   "outputs": [],
   "source": [
    "new_high_quality_samples = a.loc[a.check == 0,:].iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting to Train Test Validation and adding new samples ONLY to Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:20:18.491880Z",
     "start_time": "2021-11-12T07:20:18.461880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 137, 3758], dtype=int64),\n",
       " array([  64, 1494,    3], dtype=int64),\n",
       " array([ 45, 994,   2], dtype=int64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(index=index_high_quality).iloc[:,:-1],\n",
    "                                                    df.drop(index=index_high_quality).iloc[:,-1],test_size=.4,random_state=255)\n",
    "\n",
    "#adding high quality wines\n",
    "X_test = X_test.append(df.iloc[index_high_quality,:-1])\n",
    "y_test = y_test.append(df.iloc[index_high_quality,-1])\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test,y_test,test_size=.4,random_state=255)\n",
    "\n",
    "np.bincount(y_train), np.bincount(y_test),np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:20:19.912882Z",
     "start_time": "2021-11-12T07:20:19.892882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 137, 3758, 2994], dtype=int64),\n",
       " array([  64, 1494,    3], dtype=int64),\n",
       " array([ 45, 994,   2], dtype=int64))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding generated examples to train dataset \n",
    "X_train = X_train.append(new_high_quality_samples.iloc[:,:-1])\n",
    "y_train = y_train.append(new_high_quality_samples.iloc[:,-1])\n",
    "\n",
    "np.bincount(y_train), np.bincount(y_test),np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making 50 duplicates of class 2 in Test and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:20:28.353894Z",
     "start_time": "2021-11-12T07:20:28.323894Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  64, 1494,   50], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making 50 duplicates of high_quality wine to X_test and y_test:\n",
    "X_y_test = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "a = X_y_test[X_y_test.quality==2]\n",
    "\n",
    "a = a.sample(n=47,random_state=255,replace=True)\n",
    "\n",
    "X_y_test = pd.concat([a,X_y_test],axis=0)\n",
    "\n",
    "\n",
    "X_test = X_y_test.iloc[:,:-1]\n",
    "y_test = X_y_test.iloc[:,-1]\n",
    "\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:20:32.093899Z",
     "start_time": "2021-11-12T07:20:32.063899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45, 994,  50], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making 50 duplicates of high_quality wine to X_val and y_val:\n",
    "X_y_val = pd.concat([X_val,y_val],axis=1)\n",
    "\n",
    "a = X_y_val[X_y_val.quality==2]\n",
    "\n",
    "a = a.sample(n=48,random_state=255,replace=True)\n",
    "\n",
    "X_y_val = pd.concat([a,X_y_val],axis=0)\n",
    "\n",
    "\n",
    "X_val = X_y_val.iloc[:,:-1]\n",
    "y_val = X_y_val.iloc[:,-1]\n",
    "\n",
    "np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:20:34.503903Z",
     "start_time": "2021-11-12T07:20:34.473903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:\n",
      "0\t1\t2\n",
      "-----------------------------------\n",
      "[ 137 3758 2994]  <- train\n",
      "[  64 1494   50]  <- test\n",
      "[ 45 994  50]  <- validation\n"
     ]
    }
   ],
   "source": [
    "print('class:')\n",
    "print('0\\t1\\t2')\n",
    "print('-'*35)\n",
    "print(np.bincount(y_train), ' <- train')\n",
    "print(np.bincount(y_test), ' <- test')\n",
    "print(np.bincount(y_val), ' <- validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:20:39.344910Z",
     "start_time": "2021-11-12T07:20:39.324909Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 137, 3758, 2994], dtype=int64),\n",
       " array([  64, 1494,   50], dtype=int64),\n",
       " array([ 45, 994,  50], dtype=int64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train), np.bincount(y_test),np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T07:20:55.406932Z",
     "start_time": "2021-11-12T07:20:55.056932Z"
    }
   },
   "outputs": [],
   "source": [
    "#saving to file:\n",
    "X_train.to_csv('X_train.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "\n",
    "X_test.to_csv('X_test.csv')\n",
    "y_test.to_csv('y_test.csv')\n",
    "\n",
    "X_val.to_csv('X_val.csv')\n",
    "y_val.to_csv('y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
